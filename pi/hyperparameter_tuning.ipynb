{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHaXdDWbIq3l"
      },
      "source": [
        "# Steps to a Machine Learning Pipeline\n",
        "\n",
        "- Importing Libraries\n",
        "- Loading and Preprocessing Data \n",
        "- Creating a validation set\n",
        "- Defining the model structure \n",
        "- Training the model\n",
        "- Making predictions \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u-s76xnUAojc",
        "outputId": "32c2ecca-878f-4ef2-d5e1-c256b48acfe3"
      },
      "outputs": [],
      "source": [
        "# Mounting Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "## Uncomment to unmount\n",
        "# drive.flush_and_unmount()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2iV-u4IJUmD",
        "outputId": "facb68ed-6763-4418-e8c9-2cc1af50a737"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "csv_path = '/content/drive/MyDrive/dataset.csv'\n",
        "dataset_path = '/content/drive/MyDrive/dataset/'\n",
        "OUTPUT_PATH = '/content/drive/MyDrive/output/'\n",
        "\n",
        "print(\"dataset loaded\")\n",
        "\n",
        "# for line in open(os.path.join(file_prefix, 'clean_dataset.txt')):\n",
        "#     print(line.strip())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eMHrqqAdqgkx"
      },
      "outputs": [],
      "source": [
        "# initialize the input shape and number of classes\n",
        "INPUT_SHAPE = (28, 28, 1)\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "# define the total number of epochs to train, batch size, and the\n",
        "# early stopping patience\n",
        "EPOCHS = 50\n",
        "BS = 8\n",
        "EARLY_STOPPING_PATIENCE = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgzjxDAbKVyL"
      },
      "source": [
        "## Loading and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "lxlacMNPJcEy",
        "outputId": "558e2e35-e1a6-4d70-efe5-0fc82b8582f1"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.5.0\n",
        "\n",
        "## Importing libraries for building the model\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQhW8SKcPMJv",
        "outputId": "28118ded-f954-4ffb-a930-5c0c8a16dc85"
      },
      "outputs": [],
      "source": [
        "# Split into train and test\n",
        "dataset = pd.read_csv(csv_path)\n",
        "\n",
        "print(dataset)\n",
        "\n",
        "## Scale y label to [0, 1] range\n",
        "dataset['label'] = dataset['label'] / 100\n",
        "\n",
        "# Doing an 80/20 train/test split without evenly splitting from each label\n",
        "train, test = train_test_split(dataset, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Train label count\")\n",
        "print(train['label'].value_counts())\n",
        "\n",
        "print(\"Test label count\")\n",
        "print(test['label'].value_counts())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liW8oLu7QWiV",
        "outputId": "d6a72aa4-0779-4990-cd70-ce8918c65a76"
      },
      "outputs": [],
      "source": [
        "# Loading train images\n",
        "train_images = []\n",
        "\n",
        "train_np = train['img'].to_numpy()\n",
        "\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img_path = dataset_path + train_np[i]\n",
        "    print(img_path)\n",
        "    img = image.load_img(img_path, target_size=(28,28,1), color_mode=\"grayscale\")\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255 # normalise\n",
        "    train_images.append(img)\n",
        "\n",
        "X_train = np.array(train_images)\n",
        "\n",
        "y_train = train['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7UEjsLGZvSl4",
        "outputId": "901a57af-b8fe-4720-e3c4-807062273fa3"
      },
      "outputs": [],
      "source": [
        "# Loading test images\n",
        "test_images = []\n",
        "\n",
        "test_np = test['img'].to_numpy()\n",
        "\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    img_path = dataset_path + test_np[i]\n",
        "    print(img_path)\n",
        "\n",
        "    img = image.load_img(img_path, target_size=(28,28,1), color_mode=\"grayscale\")\n",
        "    img = image.img_to_array(img)\n",
        "    img = img/255\n",
        "    test_images.append(img)\n",
        "\n",
        "X_test = np.array(test_images)\n",
        "\n",
        "y_test = test['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqRsYp5bSbT-",
        "outputId": "de2a6f5a-43c1-44c8-f6ec-fdc45b9a53ee"
      },
      "outputs": [],
      "source": [
        "# Creating a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, random_state=44, test_size=0.1)\n",
        "\n",
        "print(\"size of train and validation set\")\n",
        "print(y_train.shape, y_val.shape)\n",
        "\n",
        "print(\"Train label count\")\n",
        "print(np.unique(y_train[:], return_counts=True))\n",
        "\n",
        "print(\"Test label count\")\n",
        "print(np.unique(y_val[:], return_counts=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YkhNdkz0rGeF"
      },
      "source": [
        "# Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfj1wAmfu0bk",
        "outputId": "194403ea-9eca-4806-ae69-ca50329d5601"
      },
      "outputs": [],
      "source": [
        "!pip install keras-tuner\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import kerastuner as kt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "06hEwBSrrJIC"
      },
      "outputs": [],
      "source": [
        "def build_model(hp):\n",
        "    model = Sequential()\n",
        "    inputShape = INPUT_SHAPE\n",
        "\n",
        "    # number of conv -> relu -> pool blocks\n",
        "    for i in range(hp.Int('conv_blocks', min_value=1, max_value=2, step=1)):\n",
        "        filters = hp.Int('conv_' + str(i), min_value=32, max_value=256, step=32)\n",
        "\n",
        "        if i == 0:\n",
        "            model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu', \n",
        "            input_shape=inputShape, padding='same'))\n",
        "        else:\n",
        "            model.add(Conv2D(filters, kernel_size=(3, 3), activation='relu',\n",
        "            padding='same'))\n",
        "\n",
        "        if hp.Choice(\"pooling_\"+ str(i), values=[\"max\", \"avg\"]) == 'max':\n",
        "            model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "        else:\n",
        "            model.add(AveragePooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout_1', 0, 0.5, step=0.1, default=0.5)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(hp.Int(\"dense_units\", min_value=128, max_value=512, step=128), \n",
        "    activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(hp.Float('dropout_2', 0, 0.5, step=0.1, default=0.5)))\n",
        "\n",
        "    activation = hp.Choice(\"output_activation\", values=[\"sigmoid\", \"relu\"])\n",
        "    model.add(Dense(NUM_CLASSES, activation=activation))\n",
        "\n",
        "    lr = hp.Float('learning_rate', 1e-4, 1e-2, sampling='log')\n",
        "\n",
        "    if hp.Choice(\"optimiser\", values =[\"adam\", \"sgd\"]) == \"adam\":\n",
        "        opt = keras.optimizers.Adam(learning_rate=lr)\n",
        "    else:\n",
        "        opt = keras.optimizers.SGD(learning_rate=lr)\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=opt, loss=\"mse\",\n",
        "    metrics=[RootMeanSquaredError()])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKx2SF-7tg78"
      },
      "outputs": [],
      "source": [
        "# initialize an early stopping callback to prevent the model from\n",
        "# overfitting/spending too much time training with minimal gains\n",
        "es = EarlyStopping(\n",
        "\tmonitor=\"val_loss\",\n",
        "\tpatience=EARLY_STOPPING_PATIENCE,\n",
        "\trestore_best_weights=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HmEKF9aatqLo"
      },
      "outputs": [],
      "source": [
        "# Using the hyperband tuning \n",
        "# The Hyperband tuner is a combination of random search with \n",
        "# “adaptive resource allocation and early stopping.” \n",
        "\n",
        "tuner = kt.Hyperband(\n",
        "\t\tbuild_model,\n",
        "\t\tobjective=kt.Objective(\"val_root_mean_squared_error\", direction=\"min\"),\n",
        "\t\tmax_epochs=EPOCHS,\n",
        "\t\tfactor=3,\n",
        "\t\tseed=42,\n",
        "\t\tdirectory=OUTPUT_PATH,\n",
        "\t\tproject_name=\"small_search\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E74SmEvut_I0",
        "outputId": "53d2ae47-da78-4848-e729-aa19e1d23019"
      },
      "outputs": [],
      "source": [
        "print(\"[INFO] performing hyperparameter search...\")\n",
        "tuner.search(\n",
        "\tx=X_train, y=y_train,\n",
        "\tvalidation_split=0.2,\n",
        "\tbatch_size=BS,\n",
        "\tcallbacks=[es],\n",
        "\tepochs=EPOCHS,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-K3gE5juKXO",
        "outputId": "3fe55584-31b6-4b78-ba03-270d663265a4"
      },
      "outputs": [],
      "source": [
        "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "print(\"[INFO] optimal number of conv blocks: {}\".format(\n",
        "\tbestHP.get(\"conv_blocks\")))\n",
        "print(\"[INFO] optimal number of filters in conv_1 layer: {}\".format(\n",
        "\tbestHP.get(\"conv_1\")))\n",
        "print(\"[INFO] optimal number of filters in conv_2 layer: {}\".format(\n",
        "\tbestHP.get(\"conv_2\")))\n",
        "print(\"[INFO] optimal type of pooling 1 layer: {}\".format(\n",
        "\tbestHP.get(\"pooling_1\")))\n",
        "print(\"[INFO] optimal type of pooling 2 layer: {}\".format(\n",
        "\tbestHP.get(\"pooling_2\")))\n",
        "print(\"[INFO] optimal dropout 1 rate: {}\".format(\n",
        "\tbestHP.get(\"dropout_1\")))\n",
        "print(\"[INFO] optimal number of units in dense layer: {}\".format(\n",
        "\tbestHP.get(\"dense_units\")))\n",
        "print(\"[INFO] optimal dropout 2 rate: {}\".format(\n",
        "\tbestHP.get(\"dropout_2\")))\n",
        "print(\"[INFO] optimal output activation function: {}\".format(\n",
        "\tbestHP.get(\"output_activation\")))\n",
        "print(\"[INFO] optimal learning rate: {:.4f}\".format(\n",
        "\tbestHP.get(\"learning_rate\")))\n",
        "print(\"[INFO] optimal optimiser: {}\".format(\n",
        "\tbestHP.get(\"optimiser\")))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8GDQy5hiBhi",
        "outputId": "744ab287-85dc-4fa6-ce3e-6346121bcbd6"
      },
      "outputs": [],
      "source": [
        "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs to find best number of epochs to train for\n",
        "model = tuner.hypermodel.build(bestHP)\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lAZxG6oqRx83",
        "outputId": "e4f1b9d8-cd8c-4dcf-e6f6-ba56cecabdb2"
      },
      "outputs": [],
      "source": [
        "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HT4PnnZ7kl5q",
        "outputId": "12b80e84-83d8-4ca4-f1a0-7cc3a5ed2ef8"
      },
      "outputs": [],
      "source": [
        "val_rmse = history.history['val_root_mean_squared_error']\n",
        "best_epoch = val_rmse.index(min(val_rmse)) + 1\n",
        "print('Best epoch: %d' % (best_epoch,))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkdSsZBOrYj9"
      },
      "source": [
        "# Training the Final Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9VhMG8hiQp0",
        "outputId": "e4420588-0fe5-4ddd-f35a-6270e0df9d08"
      },
      "outputs": [],
      "source": [
        "## Train the model again on the tuned number of epoches\n",
        "hypermodel = tuner.hypermodel.build(bestHP)\n",
        "\n",
        "# Retrain the model\n",
        "history = hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)\n",
        "\n",
        "# Evaluate\n",
        "eval_result = hypermodel.evaluate(X_test, y_test)\n",
        "print(\"[test loss, test rmse]:\", eval_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_5tbPDPR5Tb"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "After hyperparameter tuning, train the model with the tuned values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pK0SMPgFR6ZN"
      },
      "outputs": [],
      "source": [
        "model = Sequential()\n",
        "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "model.add(AveragePooling2D(pool_size=(2, 2)))\n",
        "# model.add(Conv2D(192, (3, 3), activation='relu'))\n",
        "# model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "# model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjaB6kGgSIcL"
      },
      "outputs": [],
      "source": [
        "optimizer = keras.optimizers.Adam(learning_rate=0.0008)\n",
        "\n",
        "model.compile(loss='mse', optimizer=optimizer, metrics=[RootMeanSquaredError()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9hMeUj-TKz8"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRzMfIS3TNJP",
        "outputId": "5530be81-c9de-4fc6-cbdf-e124392eda01"
      },
      "outputs": [],
      "source": [
        "self_history = model.fit(X_train, y_train, epochs=20, validation_data=(X_val, y_val), batch_size=8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDcZpYuQTRzr"
      },
      "source": [
        "## Making Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Mj0_uaOTlEC",
        "outputId": "98ed2fff-fa8d-4b74-c14b-fa00a256a1f5"
      },
      "outputs": [],
      "source": [
        "# making predictions\n",
        "prediction = model.predict(X_test)\n",
        "\n",
        "print(prediction.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Id-fc-sZTyc5"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Jzm_0YOcx14",
        "outputId": "00cceb07-b269-4f88-dbbd-707251097325"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "import math\n",
        "\n",
        "for i in range(20):\n",
        "    print(prediction[i], y_test[i])\n",
        "\n",
        "# Print R2 Score \n",
        "print(\"R2 Score: {}\".format(r2_score(y_test, prediction)))\n",
        "print(\"MSE: {}\".format(mean_squared_error(y_test, prediction)))\n",
        "print(\"RMSE: {}\".format(math.sqrt(mean_squared_error(y_test, prediction))))\n",
        "print(\"MAE: {}\".format(mean_absolute_error(y_test, prediction)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eaw1M6P-xNDz"
      },
      "source": [
        "## Saving Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6b7hG9tUvLmi"
      },
      "outputs": [],
      "source": [
        "## Save Keras SavedModel for future\n",
        "hypermodel.save('model.h5')\n",
        "\n",
        "!cp model.h5 \"/content/drive/My Drive/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLRE6Dko1QIU"
      },
      "source": [
        "## Plotting graphs for evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "MQkG--K_yNyv",
        "outputId": "add12195-e7c5-41b3-d16c-2ff8aa21407e"
      },
      "outputs": [],
      "source": [
        "plt.plot(self_history.history['loss'])\n",
        "plt.plot(self_history.history['val_loss'])\n",
        "plt.title('Training Loss Against Epochs')\n",
        "plt.ylabel('Mean Square Error Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.savefig('final.png')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nonu5_VN8kwb"
      },
      "outputs": [],
      "source": [
        "!cp final.png \"/content/drive/My Drive/\""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "fyp-model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
